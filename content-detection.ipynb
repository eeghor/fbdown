{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.vision as gcv\n",
    "from google.cloud import videointelligence_v1p1beta1 as videointelligence\n",
    "from google.oauth2 import service_account\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "import json\n",
    "import webcolors\n",
    "import langcodes\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_detection_params = gcv.types.WebDetectionParams(include_geo_results=True)\n",
    "image_context = gcv.types.ImageContext(web_detection_params=web_detection_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials must be loaded as below, otherwise there will be an error\n",
    "credentials = service_account.Credentials.from_service_account_file('credentials/ArnottsAU-8ed53827c907.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = gcv.ImageAnnotatorClient(credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image file as binary\n",
    "img = gcv.types.Image(content=open('pictures/picture_582887468579563.jpg', 'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('pictures/picture_856190784534911.jpg', 'rb').read()\n",
    "\n",
    "r = MessageToDict(client.annotate_image({'image': \n",
    "                       {'content': f}, 'image_context': image_context}), \n",
    "                  preserving_proto_field_name = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_feats = 'joy sorrow anger surprise under_exposed blurred headwear'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(what):\n",
    "    _ = r.get(f'{what}_annotations', None)\n",
    "    print(f'found {len(_) if _ else 0} {what}(s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1 face(s)\n"
     ]
    }
   ],
   "source": [
    "count('face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy: LIKELY\n",
      "sorrow: VERY_UNLIKELY\n",
      "anger: VERY_UNLIKELY\n",
      "surprise: VERY_UNLIKELY\n",
      "under_exposed: VERY_UNLIKELY\n",
      "blurred: VERY_UNLIKELY\n",
      "headwear: UNLIKELY\n"
     ]
    }
   ],
   "source": [
    "for e in face_feats:\n",
    "    print(f'{e}: {r[\"face_annotations\"][0].get(e + \"_likelihood\", None)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 0 logo(s)\n"
     ]
    }
   ],
   "source": [
    "count('logo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'logo_annotations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a386bb513d15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logo_annotations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'logo_annotations'"
     ]
    }
   ],
   "source": [
    "r['logo_annotations'][0]['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 4 label(s)\n"
     ]
    }
   ],
   "source": [
    "count('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoulder, score: 0.7711181044578552\n",
      "textile, score: 0.7127899527549744\n",
      "product, score: 0.6004652380943298\n",
      "fun, score: 0.5477446913719177\n"
     ]
    }
   ],
   "source": [
    "for l in r['label_annotations']:\n",
    "    print(f'{l[\"description\"]}, score: {l[\"score\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text in Picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 4 text(s)\n"
     ]
    }
   ],
   "source": [
    "count('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 -- language: German, text: Timla\n",
      "im Fall\n",
      "\n",
      "#2 -- language: ?, text: Timla\n",
      "#3 -- language: ?, text: im\n",
      "#4 -- language: ?, text: Fall\n"
     ]
    }
   ],
   "source": [
    "for i, t in enumerate(r['text_annotations'], 1):\n",
    "    print(f'#{i} -- language: {langcodes.Language.make(language=t[\"locale\"]).language_name() if \"locale\" in t  else \"?\"}, text: {t[\"description\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restricted Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult': 'UNLIKELY',\n",
       " 'spoof': 'VERY_UNLIKELY',\n",
       " 'medical': 'VERY_UNLIKELY',\n",
       " 'violence': 'VERY_UNLIKELY',\n",
       " 'racy': 'POSSIBLE'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['safe_search_annotation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors\n",
    "higher \"scores\" means higher confidence that the color in question is prominent in the central focus of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_color(color):\n",
    "    \n",
    "    distance_to_color = []\n",
    "    \n",
    "    for k, v in webcolors.css3_hex_to_names.items():\n",
    "        \n",
    "        # going through somthing like this: {#f0f8ff: aliceblue, #faebd7: antiquewhite}\n",
    "        \n",
    "        r,g,b = webcolors.hex_to_rgb(k)  # this converts #f0f8ff to integer RGB values\n",
    "        \n",
    "        distance_to_color.append((v, (r - color[0])**2 + (g - color[1])**2 + (b - color[2])**2))\n",
    "        \n",
    "    return min(distance_to_color, key=lambda x: x[1])[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'red': 194.0, 'green': 185.0, 'blue': 164.0} 0.15782222151756287 0.19699552655220032\n",
      "(194, 185, 164)\n",
      "closest color:  silver\n",
      "{'red': 137.0, 'green': 122.0, 'blue': 158.0} 0.02791111171245575 0.06410349905490875\n",
      "(137, 122, 158)\n",
      "closest color:  lightslategrey\n",
      "{'red': 100.0, 'green': 83.0, 'blue': 61.0} 0.06573333591222763 0.05252223461866379\n",
      "(100, 83, 61)\n",
      "closest color:  darkolivegreen\n",
      "{'red': 26.0, 'green': 24.0, 'blue': 28.0} 0.0533333346247673 0.043435897678136826\n",
      "(26, 24, 28)\n",
      "closest color:  black\n",
      "{'red': 199.0, 'green': 195.0, 'blue': 186.0} 0.1671111136674881 0.135808527469635\n",
      "(199, 195, 186)\n",
      "closest color:  silver\n",
      "{'red': 173.0, 'green': 163.0, 'blue': 143.0} 0.07844444364309311 0.10183226317167282\n",
      "(173, 163, 143)\n",
      "closest color:  rosybrown\n",
      "{'red': 160.0, 'green': 155.0, 'blue': 148.0} 0.08195555210113525 0.07075007259845734\n",
      "(160, 155, 148)\n",
      "closest color:  darkgrey\n",
      "{'red': 125.0, 'green': 121.0, 'blue': 115.0} 0.07155555486679077 0.0484808050096035\n",
      "(125, 121, 115)\n",
      "closest color:  grey\n",
      "{'red': 25.0, 'green': 26.0, 'blue': 42.0} 0.0283555556088686 0.041638415306806564\n",
      "(25, 26, 42)\n",
      "closest color:  black\n",
      "{'red': 161.0, 'green': 143.0, 'blue': 182.0} 0.014755555428564548 0.03586581349372864\n",
      "(161, 143, 182)\n",
      "closest color:  darkgrey\n"
     ]
    }
   ],
   "source": [
    "for c in r['image_properties_annotation']['dominant_colors']['colors']:\n",
    "    print(c['color'], c['pixel_fraction'], c['score'])\n",
    "    rgb_ = tuple([int(c) for c in (c['color']['red'], c['color']['green'], c['color']['blue'])])\n",
    "    print(rgb_)\n",
    "    suggested_color  = get_closest_color(rgb_)\n",
    "    print('closest color: ', suggested_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'green'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_color((0,121,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'language_code': 'ceb', 'confidence': 1.0}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['full_text_annotation']['pages'][0]['property']['detected_languages']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Text Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pages:  1\n"
     ]
    }
   ],
   "source": [
    "print('pages: ', len(r['full_text_annotation']['pages']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'language_code': 'en', 'confidence': 0.7699999809265137}]\n"
     ]
    }
   ],
   "source": [
    "for p in range(len(r['full_text_annotation']['pages'])):\n",
    "    print(r['full_text_annotation']['pages'][p]['property']['detected_languages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TimTam\\nSuper Scrummy\\nChocolate Tim Tam\\nMilkshake\\nREARNOTTS\\nTimTam\\nORIGINAL\\n'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['full_text_annotation']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Detection\n",
    "This one gives us \n",
    "* web_entities\n",
    "* visually_similar_images\n",
    "* best_guess_labels\n",
    "Note: there's an overall relevancy score for the entity, not normalized and not comparable across different image queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "web entities found: 10\n"
     ]
    }
   ],
   "source": [
    "web_ents = len(r['web_detection']['web_entities'])\n",
    "print(f'web entities found: {web_ents}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: Sundae, score: 1.578178882598877\n",
      "entity: Tim Tam, score: 0.8896999955177307\n",
      "entity: Liqueur, score: 0.8364270329475403\n",
      "entity: ?, score: 0.6556000113487244\n",
      "entity: Arnott's Biscuits, score: 0.6057000160217285\n",
      "entity: Chocolate, score: 0.5485801696777344\n",
      "entity: Flavor by Bob Holmes, Jonathan Yen (narrator) (9781515966647), score: 0.5430999994277954\n",
      "entity: Biscuit, score: 0.5418000221252441\n",
      "entity: Spain, score: 0.5078999996185303\n",
      "entity: United Arab Emirates, score: 0.5071499943733215\n"
     ]
    }
   ],
   "source": [
    "for e in r['web_detection']['web_entities']:\n",
    "    print(f'entity: {e[\"description\"] if \"description\" in e else \"?\"}, score: {e[\"score\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visually_similar_images found: 10\n"
     ]
    }
   ],
   "source": [
    "sim_imgs = len(r['web_detection']['visually_similar_images'])\n",
    "print(f'visually_similar_images found: {sim_imgs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://lookaside.fbsbx.com/lookaside/crawler/media/?media_id=1916596088657356'},\n",
       " {'url': 'https://s314.siliconimg.com/kb/content_images/2017/12/13/1496558/1513170699_709.jpg'},\n",
       " {'url': 'http://www.uhainiu.com/content/images/thumbs/000/0000678_timtam-187g.jpeg'},\n",
       " {'url': 'https://cbu01.alicdn.com/img/ibank/2017/452/396/4547693254_937679173.jpg'},\n",
       " {'url': 'http://www.totallytarget.com/wp-content/uploads/2016/02/tim-tam-1.jpg'},\n",
       " {'url': 'https://wx1.sinaimg.cn/orj360/006YBhA8gy1fm1dmmcd4aj31he0u0aep.jpg'},\n",
       " {'url': 'https://www.campbellsoupcompany.com/wp-content/uploads/sites/31/2013/11/Tim-Tam-Chocolicious.jpg'},\n",
       " {'url': 'https://s1.bukalapak.com/img/139947173/large/Biskuit_Tim_Tam_Chocolate_100g_x_3_pcs.jpg'},\n",
       " {'url': 'https://media.apnarm.net.au/media/images/2014/02/16/tim_tam_50_years-lre5y1mnzhl8vk6nnh2_fct621x468_ct677x380.JPG'},\n",
       " {'url': 'https://www.c-store.com.au/wp-content/uploads/2015/07/Tim-Tam.jpg'}]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['web_detection']['visually_similar_images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'tim tam', 'language_code': 'en'}]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['web_detection']['best_guess_labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localized Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drink, score: 0.5362362265586853\n"
     ]
    }
   ],
   "source": [
    "for o in r['localized_object_annotations']:\n",
    "    print(f'{o[\"name\"]}, score: {o[\"score\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate():\n",
    "    \"\"\"\n",
    "    using Google Vision API, annotate a photo\n",
    "    \"\"\"\n",
    "    f = open('pictures/picture_582887468579563.jpg', 'rb').read()\n",
    "\n",
    "    r = MessageToDict(client.annotate_image({'image': \n",
    "                             {'content': f}, 'image_context': image_context}), \n",
    "                                    preserving_proto_field_name = True)\n",
    "    annots = defaultdict(lambda: defaultdict())\n",
    "\n",
    "    \"\"\"\n",
    "    faces\n",
    "\n",
    "    create a dictionary like this: {'faces': {'count': 2, 'face_1': {joy: very_unlikely, sorrow: very_unlikely, \n",
    "                                                            anger: very_unlikely}}}\n",
    "    \"\"\"\n",
    "\n",
    "    def _count(what):\n",
    "\n",
    "        try:\n",
    "            return int(bool(r.get(f'{what}_annotations', None)))\n",
    "        except:\n",
    "            print(f'no {what}s')\n",
    "\n",
    "\n",
    "    annots['faces']['count'] = _count('face')\n",
    "\n",
    "    for i, face in enumerate(range(annots['faces']['count'])):\n",
    "        \n",
    "        this_face_ = []\n",
    "        for feature in r['face_annotations'][i]:\n",
    "            if '_likelihood' in feature:\n",
    "                if r['face_annotations'][i][feature].lower() in 'likely very_likely'.split():\n",
    "                    this_face_.append(feature.replace('_likelihood',''))\n",
    "\n",
    "        if this_face_:\n",
    "            annots['faces']['face_' + str(i + 1)]\n",
    "\n",
    "    \"\"\"\n",
    "    logos\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    annots['logos']['count'] = _count('logo')\n",
    "\n",
    "    if annots['logos']['count']:\n",
    "        annots['logos']['descriptions'] = [r['logo_annotations'][i]['description'].lower() \n",
    "            for i, logo in enumerate(range(annots['logos']['count']))]\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    labels\n",
    "\n",
    "    these are various labels the API decided to produce, could be anything\n",
    "    \"\"\"\n",
    "\n",
    "    annots['labels']['count'] = _count('label')\n",
    "    if annots['labels']['count']:\n",
    "        annots['labels'] = {l['description']: round(l['score'], 3) for l in r['label_annotations']}\n",
    "\n",
    "    \"\"\"\n",
    "    themes\n",
    "\n",
    "    \"\"\"\n",
    "    detected_themes = [theme for theme, likelihood in r['safe_search_annotation'].items() \n",
    "                                                    if likelihood.lower() in 'likely very_likely'.split()] \n",
    "\n",
    "    if detected_themes:\n",
    "        annots['restricted_themes'] = detected_themes\n",
    "\n",
    "    \"\"\"\n",
    "    colors\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def _get_closest_color(color):\n",
    "    \n",
    "        distance_to_color = []\n",
    "    \n",
    "        for k, v in webcolors.css3_hex_to_names.items():\n",
    "    \n",
    "            # going through something like this: {#f0f8ff: aliceblue, #faebd7: antiquewhite}\n",
    "            r,g,b = webcolors.hex_to_rgb(k)  # this converts #f0f8ff to integer RGB values\n",
    "        \n",
    "            distance_to_color.append((v, (r - color[0])**2 + (g - color[1])**2 + (b - color[2])**2))\n",
    "    \n",
    "        return min(distance_to_color, key=lambda x: x[1])[0]\n",
    "\n",
    "    clrs = defaultdict(lambda: defaultdict())\n",
    "\n",
    "    for c in r['image_properties_annotation']['dominant_colors']['colors']:\n",
    "        # create an RGB tuple and get the closest color from CCS3 palette\n",
    "        color = _get_closest_color(tuple([int(c) for c in (c['color']['red'], c['color']['green'], c['color']['blue'])]))\n",
    "        clrs[color]['pixel_fraction'] = round(c['pixel_fraction'], 3)\n",
    "        clrs[color]['score'] = round(c['score'], 3)\n",
    "\n",
    "    annots['colors'] = clrs\n",
    "\n",
    "    \"\"\"\n",
    "    full text annotation\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # note that detected languages look like [{'language_code': 'ceb', 'confidence': 1.0}]\n",
    "    try:\n",
    "        annots['languages'] = sorted([(l['language_code'], l['confidence']) \n",
    "            for p in r['full_text_annotation']['pages'] for l in p['property']['detected_languages']], \n",
    "            key=lambda x: x[1], reversed=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \"\"\"\n",
    "    web detection\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        annots['web_entities'] = {e['description'].lower(): round(e['score'], 3) \n",
    "                    for e in r['web_detection']['web_entities'] if 'description' in e}\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \"\"\"\n",
    "    localized objects\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        annots['objects'] = {o['name'].lower(): round(o['score'], 3) for o in r['localized_object_annotations']}\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = annotate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.annotate.<locals>.<lambda>()>,\n",
       "            {'faces': defaultdict(None, {'count': 1}),\n",
       "             'logos': defaultdict(None, {'count': 0}),\n",
       "             'labels': {'blue': 0.968,\n",
       "              'pink': 0.957,\n",
       "              'red': 0.955,\n",
       "              'shoulder': 0.86,\n",
       "              'fun': 0.831,\n",
       "              'girl': 0.791,\n",
       "              'standing': 0.78,\n",
       "              'arm': 0.752,\n",
       "              'human body': 0.741,\n",
       "              'mouth': 0.675},\n",
       "             'colors': defaultdict(<function __main__.annotate.<locals>.<lambda>()>,\n",
       "                         {'lightsteelblue': defaultdict(None,\n",
       "                                      {'pixel_fraction': 0.122,\n",
       "                                       'score': 0.161}),\n",
       "                          'slategrey': defaultdict(None,\n",
       "                                      {'pixel_fraction': 0.13,\n",
       "                                       'score': 0.107}),\n",
       "                          'indianred': defaultdict(None,\n",
       "                                      {'pixel_fraction': 0.042,\n",
       "                                       'score': 0.067}),\n",
       "                          'black': defaultdict(None,\n",
       "                                      {'pixel_fraction': 0.03,\n",
       "                                       'score': 0.044}),\n",
       "                          'darkblue': defaultdict(None,\n",
       "                                      {'pixel_fraction': 0.002,\n",
       "                                       'score': 0.011}),\n",
       "                          'royalblue': defaultdict(None,\n",
       "                                      {'pixel_fraction': 0.001,\n",
       "                                       'score': 0.005}),\n",
       "                          'midnightblue': defaultdict(None,\n",
       "                                      {'pixel_fraction': 0.001,\n",
       "                                       'score': 0.004}),\n",
       "                          'darkgrey': defaultdict(None,\n",
       "                                      {'pixel_fraction': 0.125,\n",
       "                                       'score': 0.115}),\n",
       "                          'mediumblue': defaultdict(None,\n",
       "                                      {'pixel_fraction': 0.0, 'score': 0.001}),\n",
       "                          'cornflowerblue': defaultdict(None,\n",
       "                                      {'pixel_fraction': 0.0,\n",
       "                                       'score': 0.001})}),\n",
       "             'web_entities': {'finger': 0.897,\n",
       "              'shoulder': 0.509,\n",
       "              'abdomen': 0.429,\n",
       "              'neck': 0.419,\n",
       "              'organ': 0.416,\n",
       "              'mouth': 0.405},\n",
       "             'objects': {'woman': 0.906,\n",
       "              'man': 0.873,\n",
       "              'person': 0.736,\n",
       "              'clothing': 0.523}})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_v = videointelligence.VideoIntelligenceServiceClient(credentials=credentials)\n",
    "\n",
    "# this API version supports 'EXPLICIT_CONTENT_DETECTION', 'FEATURE_UNSPECIFIED', \n",
    "# 'LABEL_DETECTION', 'SHOT_CHANGE_DETECTION', 'SPEECH_TRANSCRIPTION'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_config = videointelligence.types.SpeechTranscriptionConfig(language_code='en-US')\n",
    "vd_context = videointelligence.types.VideoContext(speech_transcription_config=sp_config)\n",
    "\n",
    "operation = client_v.annotate_video(input_uri='gs://timtamslam_videos/video_679808005510204.mp4', \n",
    "                                    features=[videointelligence.enums.Feature.SPEECH_TRANSCRIPTION], video_context=vd_context)\n",
    "res = operation.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_text = [_.transcript for _ in res.annotation_results[0].speech_transcriptions[0].alternatives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation = client_v.annotate_video(input_uri='gs://timtamslam_videos/video_679808005510204.mp4', \n",
    "                                    features=[videointelligence.enums.Feature.LABEL_DETECTION])\n",
    "res = operation.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ent: food, cat: \n",
      "ent: conversation, cat: communication\n",
      "ent: eating, cat: person\n",
      "ent: social group, cat: \n",
      "ent: interaction, cat: person\n"
     ]
    }
   ],
   "source": [
    "for ann in res.annotation_results[0].segment_label_annotations:\n",
    "    desc = ann.entity.description\n",
    "    cents = ' - '.join([_.description for _ in ann.category_entities])\n",
    "    print(f'ent: {desc}, cat: {cents}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ent: interaction, cat: person\n",
      "ent: social group, cat: \n",
      "ent: restaurant, cat: business\n",
      "ent: community, cat: organization\n",
      "ent: conversation, cat: communication\n",
      "ent: eating, cat: person\n",
      "ent: student, cat: person\n",
      "ent: learning, cat: person\n",
      "ent: fun, cat: \n",
      "ent: food, cat: \n",
      "ent: party, cat: event\n",
      "ent: drink, cat: \n",
      "ent: people, cat: person\n"
     ]
    }
   ],
   "source": [
    "for ann in res.annotation_results[0].shot_label_annotations:\n",
    "    desc = ann.entity.description\n",
    "    cents = ' - '.join([_.description for _ in ann.category_entities])\n",
    "    print(f'ent: {desc}, cat: {cents}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
